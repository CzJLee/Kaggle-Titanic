{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Kaggle Titanic\n",
    "\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "## What Data Will I Use in This Competition?\n",
    "\n",
    "In this competition, you’ll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n",
    "\n",
    "Train.csv will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the “ground truth”.\n",
    "\n",
    "The `test.csv` dataset contains similar information but does not disclose the “ground truth” for each passenger. It’s your job to predict these outcomes.\n",
    "\n",
    "Using the patterns you find in the train.csv data, predict whether the other 418 passengers on board (found in test.csv) survived."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-2423db62659b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "source": [
    "Let's load the training and test data set and take a look at it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train.csv\", index_col = 0)\n",
    "test_data = pd.read_csv(\"test.csv\", index_col = 0)\n",
    "train_data.head()"
   ]
  },
  {
   "source": [
    "## Data Columns\n",
    "\n",
    "Here are the different columns in the data set and what they represent\n",
    "\n",
    "| Variable | Definition                                 | Key                                            |\n",
    "|----------|--------------------------------------------|------------------------------------------------|\n",
    "| survival | Survival                                   | 0 = No, 1 = Yes                                |\n",
    "| pclass   | Ticket class                               | 1 = 1st, 2 = 2nd, 3 = 3rd                      |\n",
    "| sex      | Sex                                        |                                                |\n",
    "| Age      | Age in years                               |                                                |\n",
    "| sibsp    | # of siblings / spouses aboard the Titanic |                                                |\n",
    "| parch    | # of parents / children aboard the Titanic |                                                |\n",
    "| ticket   | Ticket number                              |                                                |\n",
    "| fare     | Passenger fare                             |                                                |\n",
    "| cabin    | Cabin number                               |                                                |\n",
    "| embarked | Port of Embarkation                        | C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "### Variable Notes\n",
    "\n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "* 1st = Upper\n",
    "* 2nd = Middle\n",
    "* 3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Let's process the data in our training set and turn them into numpy arrays that TensorFlow can handle.\n",
    "\n",
    "First, let's extract the Survived column from the train data and create our training targets. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ground truth targets from the train data. \n",
    "train_targets = train_data[\"Survived\"].to_numpy()\n",
    "\n",
    "# Remove targets from the train data\n",
    "train_data.drop(columns=[\"Survived\"], inplace=True)\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Pclass\n",
    "\n",
    "Let's examine the `Pclass` column.\n",
    "\n",
    "First, check to see if there are any missing values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_missing_values(series):\n",
    "    if series.isnull().values.any():\n",
    "        print(f\"{series.name} HAS MISSING VALUES.\")\n",
    "    else:\n",
    "        print(f\"{series.name} does not have any missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pclass does not have any missing values.\n"
     ]
    }
   ],
   "source": [
    "has_missing_values(train_data[\"Pclass\"])"
   ]
  },
  {
   "source": [
    "Great. Looks like Pclass does not have any missing values. It seems that all of the values in `Pclass` are integers, but let's double check."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_unique_values_in_series(series):\n",
    "    # Print a unique list of all values in the given pd.Series\n",
    "    print(f\"Unique values in {series.name} column: {list(series.unique())}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unique values in Pclass column: [3, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "list_unique_values_in_series(train_data['Pclass'])"
   ]
  },
  {
   "source": [
    "I now know that Pclass has no missing values, and only contains the integers 1, 2, and 3. \n",
    "\n",
    "I will come back to normalize these values at the end. As of now, let's move on to the next column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Name\n",
    "\n",
    "The name of each passenger will be hard to process. For now, let's completely ignore the passengers name and see what kind of results we get. \n",
    "\n",
    "For future implementions, I might try to one-hot encode the last name, as it could be possible that we can find relations between people with the same last name."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Name from the data sets\n",
    "train_data.drop(columns=[\"Name\"], inplace=True)\n",
    "test_data.drop(columns=[\"Name\"], inplace=True)"
   ]
  },
  {
   "source": [
    "### Sex\n",
    "\n",
    "Let's check to see if there are any missing or odd values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sex does not have any missing values.\nUnique values in Sex column: ['male', 'female']\n"
     ]
    }
   ],
   "source": [
    "has_missing_values(train_data[\"Sex\"])\n",
    "list_unique_values_in_series(train_data['Sex'])"
   ]
  },
  {
   "source": [
    "Excelent. No missing values. Let's encode these to binary values, 0 and 1. \n",
    "\n",
    "female -> 0\n",
    "\n",
    "male -> 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all the \"female\" values with 0, and all the \"male\" values with 1.\n",
    "train_data[\"Sex\"].replace([\"female\", \"male\"], [0, 1], inplace = True)\n",
    "test_data[\"Sex\"].replace([\"female\", \"male\"], [0, 1], inplace = True)"
   ]
  },
  {
   "source": [
    "### Age\n",
    "\n",
    "Let's examine the Age column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Age HAS MISSING VALUES.\nUnique values in Age column: [22.0, 38.0, 26.0, 35.0, nan, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 55.0, 31.0, 34.0, 15.0, 28.0, 8.0, 19.0, 40.0, 66.0, 42.0, 21.0, 18.0, 3.0, 7.0, 49.0, 29.0, 65.0, 28.5, 5.0, 11.0, 45.0, 17.0, 32.0, 16.0, 25.0, 0.83, 30.0, 33.0, 23.0, 24.0, 46.0, 59.0, 71.0, 37.0, 47.0, 14.5, 70.5, 32.5, 12.0, 9.0, 36.5, 51.0, 55.5, 40.5, 44.0, 1.0, 61.0, 56.0, 50.0, 36.0, 45.5, 20.5, 62.0, 41.0, 52.0, 63.0, 23.5, 0.92, 43.0, 60.0, 10.0, 64.0, 13.0, 48.0, 0.75, 53.0, 57.0, 80.0, 70.0, 24.5, 6.0, 0.67, 30.5, 0.42, 34.5, 74.0]\n"
     ]
    }
   ],
   "source": [
    "has_missing_values(train_data[\"Age\"])\n",
    "list_unique_values_in_series(train_data['Age'])"
   ]
  },
  {
   "source": [
    "So it turns out that our Age column has some missing values. \n",
    "\n",
    "One options is to remove the missing values, but then we would be losing out on data, and if our test data happens to have missing values, we would have to figure out a way to handle these anyways.\n",
    "\n",
    "Let's instead replace any missing value with the average age of all passengers aboard."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "29.69911764705882\n"
     ]
    }
   ],
   "source": [
    "mean_passenger_age = train_data[\"Age\"].mean(axis=0)\n",
    "print(mean_passenger_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Age does not have any missing values.\n"
     ]
    }
   ],
   "source": [
    "# Fill in all missing age values with the mean passenger age\n",
    "train_data[\"Age\"].fillna(value = mean_passenger_age, inplace=True)\n",
    "test_data[\"Age\"].fillna(value = mean_passenger_age, inplace=True)\n",
    "\n",
    "has_missing_values(train_data[\"Age\"])"
   ]
  },
  {
   "source": [
    "### Sibsp: Number of siblings or spouses aboard\n",
    "\n",
    "The values of this column should be an integer number.\n",
    "\n",
    "It looks like there are no mising values here."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SibSp does not have any missing values.\nUnique values in SibSp column: [1, 0, 3, 4, 2, 5, 8]\n"
     ]
    }
   ],
   "source": [
    "has_missing_values(train_data[\"SibSp\"])\n",
    "list_unique_values_in_series(train_data[\"SibSp\"])"
   ]
  },
  {
   "source": [
    "### Parch: Number of parents or children aboard\n",
    "\n",
    "The values of this column should be an integer number.\n",
    "\n",
    "It looks like there are no mising values here."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parch does not have any missing values.\nUnique values in Parch column: [0, 1, 2, 5, 3, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "has_missing_values(train_data[\"Parch\"])\n",
    "list_unique_values_in_series(train_data[\"Parch\"])"
   ]
  },
  {
   "source": [
    "# Ticket\n",
    "\n",
    "This column describes the ticket number for each passenger. There are almost as many ticket numbers as there are passengers, and they all have different formats too. Let's omit this for now. \n",
    "\n",
    "One way to handle this column would be to see if some of the prefix letters are some identifying ticket info, aside from the number. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Ticket number from the data sets\n",
    "train_data.drop(columns=[\"Ticket\"], inplace=True)\n",
    "test_data.drop(columns=[\"Ticket\"], inplace=True)"
   ]
  },
  {
   "source": [
    "### Fare \n",
    "\n",
    "This should be the cost each passenger paid for their ticket. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fare does not have any missing values.\nUnique values in Fare column: [7.25, 71.2833, 7.925, 53.1, 8.05, 8.4583, 51.8625, 21.075, 11.1333, 30.0708, 16.7, 26.55, 31.275, 7.8542, 16.0, 29.125, 13.0, 18.0, 7.225, 26.0, 8.0292, 35.5, 31.3875, 263.0, 7.8792, 7.8958, 27.7208, 146.5208, 7.75, 10.5, 82.1708, 52.0, 7.2292, 11.2417, 9.475, 21.0, 41.5792, 15.5, 21.6792, 17.8, 39.6875, 7.8, 76.7292, 61.9792, 27.75, 46.9, 80.0, 83.475, 27.9, 15.2458, 8.1583, 8.6625, 73.5, 14.4542, 56.4958, 7.65, 29.0, 12.475, 9.0, 9.5, 7.7875, 47.1, 15.85, 34.375, 61.175, 20.575, 34.6542, 63.3583, 23.0, 77.2875, 8.6542, 7.775, 24.15, 9.825, 14.4583, 247.5208, 7.1417, 22.3583, 6.975, 7.05, 14.5, 15.0458, 26.2833, 9.2167, 79.2, 6.75, 11.5, 36.75, 7.7958, 12.525, 66.6, 7.3125, 61.3792, 7.7333, 69.55, 16.1, 15.75, 20.525, 55.0, 25.925, 33.5, 30.6958, 25.4667, 28.7125, 0.0, 15.05, 39.0, 22.025, 50.0, 8.4042, 6.4958, 10.4625, 18.7875, 31.0, 113.275, 27.0, 76.2917, 90.0, 9.35, 13.5, 7.55, 26.25, 12.275, 7.125, 52.5542, 20.2125, 86.5, 512.3292, 79.65, 153.4625, 135.6333, 19.5, 29.7, 77.9583, 20.25, 78.85, 91.0792, 12.875, 8.85, 151.55, 30.5, 23.25, 12.35, 110.8833, 108.9, 24.0, 56.9292, 83.1583, 262.375, 14.0, 164.8667, 134.5, 6.2375, 57.9792, 28.5, 133.65, 15.9, 9.225, 35.0, 75.25, 69.3, 55.4417, 211.5, 4.0125, 227.525, 15.7417, 7.7292, 12.0, 120.0, 12.65, 18.75, 6.8583, 32.5, 7.875, 14.4, 55.9, 8.1125, 81.8583, 19.2583, 19.9667, 89.1042, 38.5, 7.725, 13.7917, 9.8375, 7.0458, 7.5208, 12.2875, 9.5875, 49.5042, 78.2667, 15.1, 7.6292, 22.525, 26.2875, 59.4, 7.4958, 34.0208, 93.5, 221.7792, 106.425, 49.5, 71.0, 13.8625, 7.8292, 39.6, 17.4, 51.4792, 26.3875, 30.0, 40.125, 8.7125, 15.0, 33.0, 42.4, 15.55, 65.0, 32.3208, 7.0542, 8.4333, 25.5875, 9.8417, 8.1375, 10.1708, 211.3375, 57.0, 13.4167, 7.7417, 9.4833, 7.7375, 8.3625, 23.45, 25.9292, 8.6833, 8.5167, 7.8875, 37.0042, 6.45, 6.95, 8.3, 6.4375, 39.4, 14.1083, 13.8583, 50.4958, 5.0, 9.8458, 10.5167]\n"
     ]
    }
   ],
   "source": [
    "has_missing_values(train_data[\"Fare\"])\n",
    "list_unique_values_in_series(train_data[\"Fare\"])"
   ]
  },
  {
   "source": [
    "It seems that there are no missing values, but there are some zeroes. Perhaps some passengers did get free tickets, but let's check how many to make sure it doesn't obscure our data by too much.\n",
    "\n",
    "It seems that only 15 of the passengers has a $0 fare, which is small enough that it seems valid. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8.0500     43\n13.0000    42\n7.8958     38\n7.7500     34\n26.0000    31\n           ..\n50.4958     1\n13.8583     1\n8.4583      1\n7.7250      1\n7.5208      1\nName: Fare, Length: 248, dtype: int64\nNumber of passengers with $0 fare: 15\n"
     ]
    }
   ],
   "source": [
    "print(train_data[\"Fare\"].value_counts())\n",
    "print(f'Number of passengers with $0 fare: {train_data[\"Fare\"].value_counts()[0]}')"
   ]
  },
  {
   "source": [
    "### Cabin Number\n",
    "\n",
    "It appears that there are some missing data points. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cabin HAS MISSING VALUES.\nUnique values in Cabin column: [nan, 'C85', 'C123', 'E46', 'G6', 'C103', 'D56', 'A6', 'C23 C25 C27', 'B78', 'D33', 'B30', 'C52', 'B28', 'C83', 'F33', 'F G73', 'E31', 'A5', 'D10 D12', 'D26', 'C110', 'B58 B60', 'E101', 'F E69', 'D47', 'B86', 'F2', 'C2', 'E33', 'B19', 'A7', 'C49', 'F4', 'A32', 'B4', 'B80', 'A31', 'D36', 'D15', 'C93', 'C78', 'D35', 'C87', 'B77', 'E67', 'B94', 'C125', 'C99', 'C118', 'D7', 'A19', 'B49', 'D', 'C22 C26', 'C106', 'C65', 'E36', 'C54', 'B57 B59 B63 B66', 'C7', 'E34', 'C32', 'B18', 'C124', 'C91', 'E40', 'T', 'C128', 'D37', 'B35', 'E50', 'C82', 'B96 B98', 'E10', 'E44', 'A34', 'C104', 'C111', 'C92', 'E38', 'D21', 'E12', 'E63', 'A14', 'B37', 'C30', 'D20', 'B79', 'E25', 'D46', 'B73', 'C95', 'B38', 'B39', 'B22', 'C86', 'C70', 'A16', 'C101', 'C68', 'A10', 'E68', 'B41', 'A20', 'D19', 'D50', 'D9', 'A23', 'B50', 'A26', 'D48', 'E58', 'C126', 'B71', 'B51 B53 B55', 'D49', 'B5', 'B20', 'F G63', 'C62 C64', 'E24', 'C90', 'C45', 'E8', 'B101', 'D45', 'C46', 'D30', 'E121', 'D11', 'E77', 'F38', 'B3', 'D6', 'B82 B84', 'D17', 'A36', 'B102', 'B69', 'E49', 'C47', 'D28', 'E17', 'A24', 'C50', 'B42', 'C148']\nNumber of missing cabin number values: 687\n"
     ]
    }
   ],
   "source": [
    "has_missing_values(train_data[\"Cabin\"])\n",
    "list_unique_values_in_series(train_data[\"Cabin\"])\n",
    "print(f'Number of missing cabin number values: {train_data[\"Cabin\"].isnull().sum()}')"
   ]
  },
  {
   "source": [
    "It turns out that there are a lot of missing data points. However, we still have a fair amount of good values. \n",
    "\n",
    "It appears that most cabin numbers are in the form of a letter then a number. I will assume that the letter has more importance, so let's consider the first character of each Cabin number only.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with zero\n",
    "train_data[\"Cabin\"].fillna(value = \"0\", inplace=True)\n",
    "test_data[\"Cabin\"].fillna(value = \"0\", inplace=True)\n",
    "\n",
    "# Concatenate the values, then replace using dictionary\n",
    "cabin_replace_dict = {\"0\": 0, \"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"T\": 8}\n",
    "train_data[\"Cabin\"] = train_data[\"Cabin\"].str[0].replace(cabin_replace_dict)\n",
    "test_data[\"Cabin\"] = test_data[\"Cabin\"].str[0].replace(cabin_replace_dict)"
   ]
  },
  {
   "source": [
    "### Embarked Location\n",
    "\n",
    "The last column in the data set is from where the passenger embarked. There should be three values\n",
    "* C = Cherbourg\n",
    "* Q = Queenstown\n",
    "* S = Southampton\n",
    "\n",
    "I do not know if any city is richer than each other, or how these relate to each other. To avoid possible relations, I will choose to one-hot encode these values. \n",
    "\n",
    "Since this column contians missing values, I will treat these as zeros for the one-hot encode. Since I know that the possible values are only C, Q, S, or NaN, I will use pandas.get_dummies method. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Embarked HAS MISSING VALUES.\nUnique values in Embarked column: ['S', 'C', 'Q', nan]\nNumber of missing Embarked location values: 2\n"
     ]
    }
   ],
   "source": [
    "has_missing_values(train_data[\"Embarked\"])\n",
    "list_unique_values_in_series(train_data[\"Embarked\"])\n",
    "print(f'Number of missing Embarked location values: {train_data[\"Embarked\"].isnull().sum()}')\n",
    "# Missing values at index 61 and 829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df of one_hot encoded Embarked values\n",
    "train_embark_one_hot = pd.get_dummies(train_data[\"Embarked\"])\n",
    "test_embark_one_hot = pd.get_dummies(train_data[\"Embarked\"])\n",
    "\n",
    "# Remove the orignal Embarked column\n",
    "train_data.drop(columns=[\"Embarked\"], inplace=True)\n",
    "test_data.drop(columns=[\"Embarked\"], inplace=True)\n",
    "\n",
    "# Concatenate the one_hot column\n",
    "train_data = pd.concat([train_data, train_embark_one_hot], axis=1)\n",
    "test_data = pd.concat([test_data, test_embark_one_hot], axis=1)"
   ]
  },
  {
   "source": [
    "## Normalization\n",
    "\n",
    "Great, now that all the data values have been transformed to numerical data, we should normalize them. \n",
    "\n",
    "- Pclass: Scale\n",
    "- Sex: No change\n",
    "- Age: normalize\n",
    "- SibSp: normalize\n",
    "- Parch: normalize\n",
    "- Fare: normalize\n",
    "- Cabin: Scale\n",
    "- Embarked: No Change"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "             Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  C  Q  S\nPassengerId                                                          \n1                 3    1  22.0      1      0   7.2500      0  0  0  1\n2                 1    0  38.0      1      0  71.2833      0  1  0  0\n3                 3    0  26.0      0      0   7.9250      0  0  0  1\n4                 1    0  35.0      1      0  53.1000      0  0  0  1\n5                 3    1  35.0      0      0   8.0500      0  0  0  1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 2.30864198,  0.64758698, 29.69911765,  0.52300786,  0.38159371,\n",
       "       32.20420797,  0.        ,  0.18855219,  0.08641975,  0.72278339])"
      ]
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "print(train_data.head())\n",
    "train_data.to_numpy().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}